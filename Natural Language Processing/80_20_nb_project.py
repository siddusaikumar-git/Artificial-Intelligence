# -*- coding: utf-8 -*-
"""80_20_NB_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tMqY8s_twuFab549ao_PLppmfFyPpWEP

Import all the required libraries for Naive Bayes and Deep Learning Models
"""

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
from keras.preprocessing.sequence import pad_sequences
from keras.preprocessing.text import Tokenizer
from keras.models import Sequential
from keras.layers import Dense, Embedding, GRU, LSTM, Dropout, Bidirectional
from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint
from keras.optimizers import adam_v2, rmsprop_v2
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm

"""Import pandas Read the dataset and displaying top 5 rows"""

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/SPl Topics ML in Info sec/spam.csv', encoding='ISO-8859-1') # reading the csv file using pandas dataframe.
df = df[['v1', 'v2']]
df.columns = ["classification", "sentences"]
df.head()

"""Labelled the dataset with ham to 0 and spam to 1"""

for ind in range(df.shape[0]):
  if df.iloc[ind][0] == "ham":
    df.loc[ind, "label"] = str(0)
  else:
    df.loc[ind, "label"] = str(1)

df.head()

"""created the list of sentences and lables"""

df["v1"]=df["classification"].map({'spam':1,'ham':0}) # mapping spam to 1 and ham to 0
labels_list = [val for val in range(df.shape[0])] 
unCleaned_sentences = [df.iloc[ind][1] for ind in range(df.shape[0])] # uncleaned sentences

"""Imported string library, changed all the text to lower case and cleaned the punctuations in all sentences."""

import string

remove_punct_map = dict.fromkeys(map(ord, string.punctuation))

sentences_list = []
for text in unCleaned_sentences:
  text = text.lower()
  sentences_list.append(text.translate(remove_punct_map))  # cleaning of sentences.

len(sentences_list)

"""Imported nltk library and downloaded the stopwords and removed it from each sentences"""

import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('punkt')
from nltk.tokenize import word_tokenize

sentences = []
for sent in sentences_list:
  text_tokens = word_tokenize(sent)
  sentences.append([word for word in text_tokens if not word in stopwords.words()]) # removing stop words from each senetence.

sentences

"""Imported Lemmatizer from nltk and lemmatized each word for each sentence in the corpus."""

from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()
nltk.download('wordnet')  # downloaded wordnet corpus data which is reference to lemmatization.

lemt_sentences = []
for sent in sentences:
  sent_l = []
  for word in sent:
    sent_l.append(wordnet_lemmatizer.lemmatize(word)) # lemmatizing each word in sentence.
  lemt_sentences.append(sent_l) # adding lemmatized sentences to list.

"""Tokenizing all the words in the corpus of data, converted texts to sequences for all sentences in the data."""

tokenizer = Tokenizer()
tokenizer.fit_on_texts(lemt_sentences)
sequences = tokenizer.texts_to_sequences(lemt_sentences)

vocab_size = len(tokenizer.word_index)+1
print(vocab_size)

"""Displayed the word length of all sentences in the corpus of data."""

plotval = [len(val) for val in sequences]

plt.plot(plotval)

"""Percentage of sentences with length of words less than or equal to 20 is 95.8%"""

sum_val = [1 if val <= 20 else 0 for val in plotval]
sum(sum_val)/len(sum_val)

"""each sequence is fixed to constant length of 20, by truncating and padding the sequences at the end of each sentence."""

pad = 'post' 
max_len = 20  # based on above analysis max length of words in a sentence is taken as 20.
embedding_size = 100    # Embedding dimension 
batch_size = 20 # batch size sent as input to neural network

sequences = pad_sequences(sequences, maxlen=max_len, padding=pad, truncating=pad) # post padding and truncating done to make sequence length of 20.

print(sequences.shape) # we got 5572 sequence with each sequence lenght of 20

X_train, X_test, y_train, y_test = train_test_split(sequences, df["v1"], test_size = 0.2, random_state= 42)

"""Displayed the bar plot of counts of spam and ham in the dataset."""

import matplotlib.pyplot as plt

dist_output_counts = df['label'].value_counts()

dist_output_counts.plot(kind='bar', color=['blue', 'red'])

plt.show()

"""Percentage distribution of spam and ham in dataset"""

dist_output_counts.plot(kind = 'pie',  autopct='%1.0f%%')
plt.title('Pie chart')
plt.ylabel('')
plt.show()

"""Dispayed the top five more frequent words in the sentences of dataset which are part of ham"""

from collections import Counter

v = " ".join(df[df['classification'] == 'ham']['sentences']).split()
traindf = Counter(v).most_common(20)

traindf = pd.DataFrame.from_dict(traindf)

traindf = traindf.rename(columns={0: "words in ham", 1: "counts"})
traindf.head()

"""Dispayed the top five more frequent words in the sentences of dataset which are part of spam"""

s = Counter(" ".join(df[df['classification'] == 'spam']['sentences']).split()).most_common(20)

df2 = pd.DataFrame.from_dict(s)
df2 = df2.rename(columns={0: "words in spam", 1: "count"})
df2.head()

"""Dispayed the top 10 more frequent words in the sentences of dataset which are part of ham"""

import numpy as np

traindf.plot.bar(legend = False)
y_pos = np.arange(len(traindf["words in ham"]))
plt.xticks(y_pos, traindf["words in ham"])
plt.title('More frequent words in non-spam messages')
plt.xlabel('words')
plt.ylabel('number')
plt.show()

"""Dispayed the top 10 more frequent words in the sentences of dataset which are part of spam"""

df2.plot.bar(legend = False)
y_pos = np.arange(len(df2["words in spam"]))
plt.xticks(y_pos, df2["words in spam"])
plt.title('More frequent words in spam messages')
plt.xlabel('words')
plt.ylabel('number')
plt.show()

"""Imported feature_extraction and created count vectorizer for stop words in english and transformed the data"""

from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm

f = feature_extraction.text.CountVectorizer(stop_words = 'english')

X = f.fit_transform(df['sentences']) # converted all sentences to vectors

np.shape(X)

"""splitted the input data to train 80% and test 20% with random state 42 """

nb_X_train, nb_X_test, nb_y_train, nb_y_test = train_test_split(X, df["v1"], test_size = 0.2, random_state= 42)

"""calculated the scores various alphas to identify the best alpha for multinomiual naive bayes."""

list_alpha = np.arange(1/100000, 20, 0.11)
score_train = np.zeros(len(list_alpha))
score_test = np.zeros(len(list_alpha))
recall_test = np.zeros(len(list_alpha))
precision_test= np.zeros(len(list_alpha))
count = 0
for alpha in list_alpha:
    bayes = naive_bayes.MultinomialNB(alpha=alpha)
    bayes.fit(nb_X_train, nb_y_train)
    score_train[count] = bayes.score(nb_X_train, nb_y_train)
    score_test[count]= bayes.score(nb_X_test, nb_y_test)
    recall_test[count] = metrics.recall_score(nb_y_test, bayes.predict(nb_X_test))
    precision_test[count] = metrics.precision_score(nb_y_test, bayes.predict(nb_X_test))
    count = count + 1

"""Displayed matrix of scores for train and test data to identify the best alpha"""

matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test])
matrix

models = pd.DataFrame(data = matrix, columns = 
             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])
models.head(n=10)

"""Identify the alpha for best test precision"""

best_index = models['Test Precision'].idxmax()
models.iloc[best_index, :]

"""Display top five best alpha with test precision 1"""

models[models['Test Precision']==1].head(n=5)

"""calculated the best alpha with test precision 1 and best test accuracy"""

best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()
bayes = naive_bayes.MultinomialNB(alpha=list_alpha[best_index])
bayes.fit(nb_X_train, nb_y_train)
models.iloc[best_index, :]

"""calculated the confusion matrix for test naive bayes dataset"""

nb_pred = bayes.predict(nb_X_test)
nb_cm = metrics.confusion_matrix(nb_y_test, bayes.predict(nb_X_test))

import seaborn as sns

group_names = ['nb_TN','nb_FP','nb_FN','nb_TP']
group_counts = ["{0:0.0f}".format(value) for value in
                nb_cm.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     nb_cm.flatten()/np.sum(nb_cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
nb_labels = np.asarray(labels).reshape(2,2)
sns.heatmap(nb_cm, annot=nb_labels, fmt='', cmap='Blues')

"""calculated the roc curve for naive bayes classifier"""

from sklearn.metrics import roc_curve, auc
from sklearn.metrics import precision_recall_curve

nb_fpr, nb_tpr, _ = roc_curve(nb_y_test, nb_pred)

plt.plot(nb_fpr, nb_tpr, linestyle='--', label='Naive Bayes ROC Curve')
plt.legend()

"""calculated the PR Curve for naive bayes classifier"""

nb_precision, nb_recall, _ = precision_recall_curve(nb_y_test, nb_pred)

plt.plot(nb_recall, nb_precision, marker='.', label='Naive Bayes PR Curve')
plt.legend()

"""Imported the libraries for deep learning models"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score, train_test_split
from keras.preprocessing.sequence import pad_sequences
from keras.preprocessing.text import Tokenizer
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, GRU, Dropout, Bidirectional
from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint
from keras.optimizers import adam_v2, rmsprop_v2
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV
from keras.utils.vis_utils import plot_model

"""created sequential model for lstm"""

model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))

model.add(LSTM(140, return_sequences=False))

model.add(Dense(1, activation='sigmoid', name='Classification'))
model.summary()

"""Displayed plot for the created sequential model"""

plot_model(model, "model.png", show_shapes=True)

"""compiled model with loss functions, optimizers and metrics."""

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""trained model with 10 epochs"""

n_epochs = 10
results = model.fit(np.array(X_train), np.array(y_train), epochs=n_epochs, batch_size=batch_size, verbose=1)

"""Evaluated lstm model on test data"""

eval_ = model.evaluate(np.array(X_test), np.array(y_test))
print(eval_[0], eval_[1]) # loss / accuracy

"""Calculated predicted outputs for lstm"""

lstm_pred = [1 if val > 0.5 else 0 for val in model.predict(np.array(X_test))]

"""confusion matrix for lstm predicted and actual output"""

lstm_cm = metrics.confusion_matrix(y_test, lstm_pred)
# pd.DataFrame(data = cm, columns = ['Predicted 0', 'Predicted 1'], index = ['Actual 0', 'Actual 1'])
group_names = ['lstm_TN','lstm_FP','lstm_FN','lstm_TP']
group_counts = ["{0:0.0f}".format(value) for value in
                lstm_cm.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     lstm_cm.flatten()/np.sum(lstm_cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
lstm_labels = np.asarray(labels).reshape(2,2)
sns.heatmap(lstm_cm, annot=lstm_labels, fmt='', cmap='Blues')

"""ROC curve for lstm calculated output"""

lstm_fpr, lstm_tpr, _ = roc_curve(y_test, lstm_pred)

plt.plot(lstm_fpr, lstm_tpr, linestyle='--', label='LSTM ROC Curve')
plt.legend()

"""PR Curve for LSTM calculated output"""

lstm_precision, lstm_recall, _ = precision_recall_curve(y_test, lstm_pred)

plt.plot(lstm_recall, lstm_precision, marker='.', label='LSTM PR Curve')
plt.legend()

"""created sequential model for GRU and trained for input training data

---


"""

model1 = Sequential()
model1.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))
model1.add(Dropout(0.8))
model1.add(GRU(140, return_sequences=False))
model1.add(Dropout(0.86))
model1.add(Dense(1, activation='sigmoid', name='Classification'))
model1.summary()

model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
results1 = model1.fit(np.array(X_train), np.array(y_train), epochs=n_epochs, batch_size=batch_size, validation_split=0.2)

"""Printed the plot for GRU model"""

plot_model(model1, "model1.png", show_shapes=True)

gru_pred = [1 if val > 0.5 else 0 for val in model1.predict(np.array(X_test))]

gru_cm = metrics.confusion_matrix(y_test, gru_pred)
# pd.DataFrame(data = gru_cm, columns = ['Predicted 0', 'Predicted 1'], index = ['Actual 0', 'Actual 1'])

group_names = ['gru_TN','gru_FP','gru_FN','gru_TP']
group_counts = ["{0:0.0f}".format(value) for value in
                gru_cm.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     gru_cm.flatten()/np.sum(gru_cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
gru_labels = np.asarray(labels).reshape(2,2)
sns.heatmap(gru_cm, annot=gru_labels, fmt='', cmap='Blues')

gru_fpr, gru_tpr, _ = roc_curve(y_test, gru_pred)

plt.plot(gru_fpr, gru_tpr, linestyle='--', label='GRU ROC Curve')
plt.legend()

gru_precision, gru_recall, _ = precision_recall_curve(y_test, gru_pred)

plt.plot(gru_recall, gru_precision, marker='.', label='GRU PR Curve')
plt.legend()

"""created sequential model for Bi-Directional LSTM and trained for input training data

"""

model2 = Sequential()
model2.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))
model2.add(Dropout(0.8))
model2.add(Bidirectional(LSTM(140, return_sequences=False)))
model2.add(Dropout(0.8))
model2.add(Dense(1, activation='sigmoid', name='Classification'))
model2.summary()

model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

results2 = model2.fit(np.array(X_train), np.array(y_train), epochs=n_epochs, batch_size=batch_size, validation_split=0.2)

"""Plotted the graph for input model of Bi-Directional lstm"""

plot_model(model2, "model2.png", show_shapes=True)

"""Confusion matrix for Bi-Directional lstm output"""

bilstm_pred = [1 if val > 0.5 else 0 for val in model2.predict(np.array(X_test))]

bilstm_cm = metrics.confusion_matrix(y_test, bilstm_pred)

group_names = ['bilstm_TN','bilstm_FP','bilstm_FN','bilstm_TP']
group_counts = ["{0:0.0f}".format(value) for value in
                bilstm_cm.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     bilstm_cm.flatten()/np.sum(bilstm_cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
bilstm_labels = np.asarray(labels).reshape(2,2)
sns.heatmap(bilstm_cm, annot=bilstm_labels, fmt='', cmap='Blues')

"""Bi-Directional lstm output ROC curve"""

bilstm_fpr, bilstm_tpr, _ = roc_curve(y_test, bilstm_pred)

plt.plot(bilstm_fpr, bilstm_tpr, linestyle='--', label='Bi-LSTM ROC Curve')
plt.legend()

"""Bi-Directional output PR Curve"""

bilstm_precision, bilstm_recall, _ = precision_recall_curve(y_test, bilstm_pred)

plt.plot(bilstm_recall, bilstm_precision, marker='.', label='Bi-LSTM PR Curve')
plt.legend()

"""Convolutional Neural Network Model and training"""

from keras.layers import Conv1D, MaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D

n_epochs = 10
model3 = Sequential()
model3.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))
model3.add(Conv1D(128, 3, activation='relu'))
model3.add(MaxPool1D(3))
model3.add(Dropout(0.2))
model3.add(Conv1D(128, 3, activation='relu'))
model3.add(GlobalMaxPooling1D())
model3.add(Dropout(0.2))
model3.add(Dense(64, activation='relu'))
model3.add(Dropout(0.2))
model3.add(Dense(32, activation='relu'))
model3.add(Dropout(0.2))
model3.summary()
model3.add(Dense(1, activation='sigmoid'))


model3.compile(loss='binary_crossentropy', optimizer="adam", metrics=['accuracy'])
result3 = model3.fit(np.array(X_train), np.array(y_train), batch_size = batch_size, epochs=n_epochs, validation_split=0.2, verbose=1)

"""Graph for CNN model"""

plot_model(model3, "model3.png", show_shapes=True)

"""CNN output and confusion matrix"""

cnn_pred = [1 if val > 0.5 else 0 for val in model3.predict(np.array(X_test))]

cnn_cm = metrics.confusion_matrix(y_test, cnn_pred)
# pd.DataFrame(data = cnn_cm, columns = ['Predicted 0', 'Predicted 1'], index = ['Actual 0', 'Actual 1'])

group_names = ['cnn_TN','cnn_FP','cnn_FN','cnn_TP']
group_counts = ["{0:0.0f}".format(value) for value in
                cnn_cm.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cnn_cm.flatten()/np.sum(cnn_cm)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
cnn_labels = np.asarray(labels).reshape(2,2)
sns.heatmap(cnn_cm, annot=cnn_labels, fmt='', cmap='Blues')

"""CNN output ROC curve"""

cnn_fpr, cnn_tpr, _ = roc_curve(y_test, cnn_pred)

plt.plot(cnn_fpr, cnn_tpr, linestyle='--', label='CNN ROC Curve')
plt.legend()

"""CNN output PR curve"""

cnn_precision, cnn_recall, _ = precision_recall_curve(y_test, cnn_pred)

plt.plot(cnn_recall, cnn_precision, marker='.', label='CNN PR Curve')
plt.legend()

"""Comparision of ROC curves between LSTM, GRU, Bi-LSTM, CNN"""

nb_roc_auc = auc(nb_fpr, nb_tpr)
lstm_roc_auc = auc(lstm_fpr, lstm_tpr)
gru_roc_auc = auc(gru_fpr, gru_tpr)
bilstm_roc_auc = auc(bilstm_fpr, bilstm_tpr)
cnn_roc_auc = auc(cnn_fpr, cnn_tpr)

plt.plot(nb_fpr, nb_tpr, color= 'red', linestyle='--', label='Naive Bayes ROC Curve (area = %0.3f)' % nb_roc_auc)
plt.plot(lstm_fpr, lstm_tpr, color= 'green', linestyle='--', label='LSTM ROC Curve (area = %0.3f)' % lstm_roc_auc)
plt.plot(bilstm_fpr, bilstm_tpr, color= 'blue', linestyle='--', label='Bi-LSTM ROC Curve (area = %0.3f)' % bilstm_roc_auc)
plt.plot(gru_fpr, gru_tpr, color= 'orange', linestyle='--', label='GRU ROC Curve (area = %0.3f)' % gru_roc_auc)
plt.plot(cnn_fpr, cnn_tpr, color= 'violet', linestyle='--', label='CNN ROC Curve (area = %0.3f)' % cnn_roc_auc)

# Plot ROC curve
plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve

plt.xlim([0.0, 1.0])

plt.ylim([0.0, 1.0])

plt.xlabel('False Positive Rate or (1 - Specifity)')

plt.ylabel('True Positive Rate or (Sensitivity)')

plt.title('80-20 Receiver Operating Characteristic')

plt.legend(loc="lower right")

plt.show()

"""Comparision of PR curves between LSTM, GRU, Bi-LSTM, CNN"""

plt.plot(nb_recall, nb_precision, color= 'red', linestyle='--', label='Naive Bayes PR Curve')
plt.plot(lstm_recall, lstm_precision, color= 'green', linestyle='--', label='LSTM PR Curve')
plt.plot(bilstm_recall, bilstm_precision, color= 'blue', linestyle='--', label='Bi-LSTM PR Curve')
plt.plot(gru_recall, gru_precision, color= 'orange', linestyle='--', label='GRU PR Curve')
plt.plot(cnn_recall, cnn_precision, color= 'violet', linestyle='--', label='CNN PR Curve')

plt.xlabel('Recall')

plt.ylabel('Precision')

plt.title('80-20 Precision-Recall curve')

plt.legend(loc="lower left")

plt.show()

"""Comparision of Metrics between LSTM, GRU, Bi-LSTM, CNN"""

ndf = pd.DataFrame({"Models":[], "Accuracies": [], "Precision": [], "Recall": []})

ndf.loc[0, "Models"] = "Naive Bayes"
ndf.loc[0, "Accuracies"] = str((nb_cm[0][0] + nb_cm[1][1])/(nb_cm[0][0] + nb_cm[0][1] + nb_cm[1][0] + nb_cm[1][1]))
ndf.loc[0, "Precision"] = str((nb_cm[1][1])/(nb_cm[0][1] + nb_cm[1][1]))
ndf.loc[0, "Recall"] = str((nb_cm[1][1])/(nb_cm[1][0] + nb_cm[1][1]))

ndf.loc[1, "Models"] = "LSTM"
ndf.loc[1, "Accuracies"] = str((lstm_cm[0][0] + lstm_cm[1][1])/(lstm_cm[0][0] + lstm_cm[0][1] + lstm_cm[1][0] + lstm_cm[1][1]))
ndf.loc[1, "Precision"] = str((lstm_cm[1][1])/(lstm_cm[0][1] + lstm_cm[1][1]))
ndf.loc[1, "Recall"] = str((lstm_cm[1][1])/(lstm_cm[1][0] + lstm_cm[1][1]))

ndf.loc[2, "Models"] = "GRU"
ndf.loc[2, "Accuracies"] = str((gru_cm[0][0] + gru_cm[1][1])/(gru_cm[0][0] + gru_cm[0][1] + gru_cm[1][0] + gru_cm[1][1]))
ndf.loc[2, "Precision"] = str((gru_cm[1][1])/(gru_cm[0][1] + gru_cm[1][1]))
ndf.loc[2, "Recall"] = str((gru_cm[1][1])/(gru_cm[1][0] + gru_cm[1][1]))

ndf.loc[3, "Models"] = "Bi-Directional LSTM"
ndf.loc[3, "Accuracies"] = str((bilstm_cm[0][0] + bilstm_cm[1][1])/(bilstm_cm[0][0] + bilstm_cm[0][1] + bilstm_cm[1][0] + bilstm_cm[1][1]))
ndf.loc[3, "Precision"] = str((bilstm_cm[1][1])/(bilstm_cm[0][1] + bilstm_cm[1][1]))
ndf.loc[3, "Recall"] = str((bilstm_cm[1][1])/(bilstm_cm[1][0] + bilstm_cm[1][1]))

ndf.loc[4, "Models"] = "CNN"
ndf.loc[4, "Accuracies"] = str((cnn_cm[0][0] + cnn_cm[1][1])/(cnn_cm[0][0] + cnn_cm[0][1] + cnn_cm[1][0] + cnn_cm[1][1]))
ndf.loc[4, "Precision"] = str((cnn_cm[1][1])/(cnn_cm[0][1] + cnn_cm[1][1]))
ndf.loc[4, "Recall"] = str((cnn_cm[1][1])/(cnn_cm[1][0] + cnn_cm[1][1]))

ndf.head()

"""Comparision of Confusion matrices between LSTM, GRU, Bi-LSTM, CNN"""

import seaborn as sns
import matplotlib.pyplot as plt
fig, axes = plt.subplots(2, 2, figsize=(10, 6))

sns.heatmap(ax=axes[0,0], data=lstm_cm, annot=lstm_labels, fmt='', cmap='Blues')
sns.heatmap(ax=axes[0,1], data=gru_cm, annot=gru_labels, fmt='', cmap='Blues' )
sns.heatmap(ax=axes[1,0], data=bilstm_cm, annot=bilstm_labels, fmt='', cmap='Blues' )
sns.heatmap(ax=axes[1,1], data=cnn_cm, annot=cnn_labels, fmt='', cmap='Blues')