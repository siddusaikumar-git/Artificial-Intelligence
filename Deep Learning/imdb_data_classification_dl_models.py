# -*- coding: utf-8 -*-
"""IMDB_Data_classification_DL_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xr4uafzGRL_MvIk83vcDzPGaVwPUFyyA

# Deep Neural Networks on IMDB Analysis Data
1. LSTM
2. CNN
3. GRU
4. BiDirectional GRU
5. Bidirectional CNN

*Import Libraries and loading Data*
"""

!pip install contractions
import pandas as pd
import numpy as np
import re
import string
import contractions

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn import preprocessing, model_selection
from keras import Sequential
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical
from keras import layers, models, optimizers

df = pd.read_csv("/content/drive/My Drive/ML_Data/IMDB Dataset.csv")

x = df['review']
y = df['sentiment']

df.head()

"""*Noise Removal and Normalizing Data*"""

def normalize_text(sentence):
  sentence = sentence.strip()  # removes the starting and ending spaces
  sentence = re.sub(r'(https|http)?:\/\/(\w|\.|\/|\?|\=|\&|\%)*\b', '', sentence) # removes links with http/https
  sentence = re.sub(r'[\[].*\]', '', sentence) # removes square brackets and text present inside it.
  sentence = sentence.translate(str.maketrans('', '', string.punctuation)) # removes punctuation.
  sentence = contractions.fix(sentence) # fixes contractions
  sentence = sentence.lower() # converts to lower case
  return sentence

x = x.apply(lambda val : normalize_text(val))

label = preprocessing.LabelEncoder()
y = label.fit_transform(y)

# # Encoding the input text

# count_label = CountVectorizer(analyzer='word', token_pattern=r'\w{1,}')
# x_count = count_label.fit_transform(x)

# tfidf_word_label = TfidfVectorizer(analyzer='word', token_pattern=r'\w{1,}', max_features=5000)
# x_tfidf_word = tfidf_word_label.fit_transform(x)

# tfidf_ngram_word_label = TfidfVectorizer(analyzer='word', ngram_range=(2, 3), token_pattern=r'\w{1,}', max_features=5000)
# x_ngram_tfidf_word = tfidf_ngram_word_label.fit_transform(x)

# tfidf_char_label = TfidfVectorizer(analyzer='char', token_pattern=r'\w{1,}', max_features=5000)
# x_tfidf_char = tfidf_char_label.fit_transform(x)

# tfidf_ngram_char_label = TfidfVectorizer(analyzer='char', ngram_range=(2, 3), token_pattern=r'\w{1,}', max_features=5000)
# x_ngram_tfidf_char = tfidf_ngram_char_label.fit_transform(x)

# x_train_count, x_test_count, y_train, y_test = train_test_split(x_count, y, test_size=0.2, random_state=42)

# x_train_tfidf_word, x_test_tfidf_word, y_train, y_test = train_test_split(x_tfidf_word, y, test_size=0.2, random_state=42)

# x_train_ngram_tfidf_word, x_test_ngram_tfidf_word, y_train, y_test = train_test_split(x_ngram_tfidf_word, y, test_size=0.2, random_state=42)

# x_train_tfidf_char,  x_test_tfidf_char, y_train, y_test = train_test_split(x_tfidf_char, y, test_size=0.2, random_state=42)

# x_train_ngram_tfidf_char,  x_test_ngram_tfidf_char, y_train, y_test = train_test_split(x_ngram_tfidf_char, y, test_size=0.2, random_state=42)

"""*Encoding /Tokenizing the Data*"""

token = Tokenizer()
token.fit_on_texts(x)

word_index = token.word_index

x = pad_sequences(token.texts_to_sequences(x), maxlen=70)

x_train_seq, x_test_seq, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# y_train = to_categorical(y_train)

"""*Training, Predicting Test data and Calculating Accuracy*"""

from sklearn.metrics import accuracy_score, f1_score, classification_report

def NN_model_training(model, x_train, y_train, x_test, y_test):

  model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.2 )

  y_pred = model.predict_classes(x_test)

  return accuracy_score(y_pred, y_test)

accuracyAnalysis = {}

"""*LSTM Model Analysis*"""

def LSTM_classification(x_train_seq):

  model = Sequential()
  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))
  model.add(layers.LSTM(100))
  model.add(layers.Dense(50, activation='relu'))
  model.add(layers.Dropout(0.2))
  model.add(layers.Dense(1, activation='sigmoid'))
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
  model.summary()

  return model

model = LSTM_classification(x_train_seq)

accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)

print("LSTM accuracy score: ", accuracy)
accuracyAnalysis["LSTM accuracy score"] = accuracy



"""*CNN Model Analysis*"""

def CNN_classification(x_train_seq):

  model = Sequential()
  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))
  model.add(layers.SpatialDropout1D(0.3))
  model.add(layers.Convolution1D(100, 3, activation='relu'))
  model.add(layers.GlobalMaxPool1D())
  model.add(layers.Dense(100, activation='relu'))
  model.add(layers.Dropout(0.25))
  model.add(layers.Dense(1, activation='sigmoid'))

  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

  model.summary()

  return model
model = CNN_classification(x_train_seq)

accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)

print("CNN accuracy score: ", accuracy)
accuracyAnalysis["CNN accuracy score"] = accuracy

"""*GRU Model Analysis*"""

def GRU_classification(x_train_seq):

  model = Sequential()
  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))
  model.add(layers.SpatialDropout1D(0.3))
  model.add(layers.GRU(100))
  model.add(layers.Dense(50, activation='relu'))
  model.add(layers.Dropout(0.2))
  model.add(layers.Dense(1, activation='sigmoid'))
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
  model.summary()

  return model

model = GRU_classification(x_train_seq)

accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)

print("GRU accuracy score: ", accuracy)
accuracyAnalysis["GRU accuracy score"] = accuracy

"""*BiDirectional GRU Model Analysis*"""

def BiDirectional_GRU_classification(x_train_seq):

  model = Sequential()
  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))
  model.add(layers.SpatialDropout1D(0.3))
  model.add(layers.Bidirectional(layers.GRU(100)))
  model.add(layers.Dense(50, activation='relu'))
  model.add(layers.Dropout(0.2))
  model.add(layers.Dense(1, activation='sigmoid'))
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
  model.summary()

  return model

model = BiDirectional_GRU_classification(x_train_seq)

accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)

print("BiDirectional GRU accuracy score: ", accuracy)
accuracyAnalysis["BiDirectional GRU accuracy score"] = accuracy

"""*BiDirectional CNN Analysis*"""

def BiDirectional_CNN_classification(x_train_seq):

  model = Sequential()
  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))
  model.add(layers.SpatialDropout1D(0.3))
  model.add(layers.Bidirectional(layers.GRU(50, return_sequences=True)))
  model.add(layers.Convolution1D(100, 3, activation='relu'))
  model.add(layers.GlobalMaxPool1D())
  model.add(layers.Dense(100, activation='relu'))
  model.add(layers.Dropout(0.25))
  model.add(layers.Dense(1, activation='sigmoid'))

  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

  model.summary()

  return model
model = BiDirectional_CNN_classification(x_train_seq)

accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)

print("BiDirectional CNN accuracy score: ", accuracy)
accuracyAnalysis["BiDirectional CNN accuracy score"] = accuracy

accuracyAnalysis
metrics = sorted(accuracyAnalysis.items(), key=(lambda x: x[1]), reverse=True)
metrics

import matplotlib.pyplot as plt
!matplotlib inline

x_metrics = []
y_metrics = []

for i in metrics:
  x_metrics.append(i[0])
  y_metrics.append(i[1])


plt.xlabel("Classification Models for text Data Using DL Techniques")
plt.ylabel("Accuracy Score")
# plt.plot(x_metrics_lemmet, y_metrics_lemmet)
plt.bar(x_metrics, y_metrics)
plt.xticks(x_metrics, rotation='vertical')
plt.show()

