{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrvRTi-j8liK"
      },
      "source": [
        "# Deep Neural Networks on IMDB Analysis Data\n",
        "1. LSTM\n",
        "2. CNN\n",
        "3. GRU\n",
        "4. BiDirectional GRU\n",
        "5. Bidirectional CNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQzJlsNtsMCE"
      },
      "source": [
        "*Import Libraries and loading Data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrJ_Dbr88sUU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "7bdc4888-2c95-4e3c-a302-52aafd81c8f3"
      },
      "source": [
        "!pip install contractions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import contractions\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing, model_selection\n",
        "from keras import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers, models, optimizers\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/ML_Data/IMDB Dataset.csv\")\n",
        "\n",
        "x = df['review']\n",
        "y = df['sentiment']\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.24)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCReSKywtngR"
      },
      "source": [
        "*Noise Removal and Normalizing Data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeQAMavjApHq"
      },
      "source": [
        "def normalize_text(sentence):\n",
        "  sentence = sentence.strip()  # removes the starting and ending spaces\n",
        "  sentence = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', sentence) # removes links with http/https\n",
        "  sentence = re.sub(r'[\\[].*\\]', '', sentence) # removes square brackets and text present inside it.\n",
        "  sentence = sentence.translate(str.maketrans('', '', string.punctuation)) # removes punctuation.\n",
        "  sentence = contractions.fix(sentence) # fixes contractions\n",
        "  sentence = sentence.lower() # converts to lower case\n",
        "  return sentence\n",
        "\n",
        "x = x.apply(lambda val : normalize_text(val))\n",
        "\n",
        "label = preprocessing.LabelEncoder()\n",
        "y = label.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOK7OcB1AqWb"
      },
      "source": [
        "# # Encoding the input text\n",
        "\n",
        "# count_label = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "# x_count = count_label.fit_transform(x)\n",
        "\n",
        "# tfidf_word_label = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "# x_tfidf_word = tfidf_word_label.fit_transform(x)\n",
        "\n",
        "# tfidf_ngram_word_label = TfidfVectorizer(analyzer='word', ngram_range=(2, 3), token_pattern=r'\\w{1,}', max_features=5000)\n",
        "# x_ngram_tfidf_word = tfidf_ngram_word_label.fit_transform(x)\n",
        "\n",
        "# tfidf_char_label = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "# x_tfidf_char = tfidf_char_label.fit_transform(x)\n",
        "\n",
        "# tfidf_ngram_char_label = TfidfVectorizer(analyzer='char', ngram_range=(2, 3), token_pattern=r'\\w{1,}', max_features=5000)\n",
        "# x_ngram_tfidf_char = tfidf_ngram_char_label.fit_transform(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0BDsCJKAsib"
      },
      "source": [
        "# x_train_count, x_test_count, y_train, y_test = train_test_split(x_count, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# x_train_tfidf_word, x_test_tfidf_word, y_train, y_test = train_test_split(x_tfidf_word, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# x_train_ngram_tfidf_word, x_test_ngram_tfidf_word, y_train, y_test = train_test_split(x_ngram_tfidf_word, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# x_train_tfidf_char,  x_test_tfidf_char, y_train, y_test = train_test_split(x_tfidf_char, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# x_train_ngram_tfidf_char,  x_test_ngram_tfidf_char, y_train, y_test = train_test_split(x_ngram_tfidf_char, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mhQmyqgtxGC"
      },
      "source": [
        "*Encoding /Tokenizing the Data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe6K8MheKffd"
      },
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(x)\n",
        "\n",
        "word_index = token.word_index\n",
        "\n",
        "x = pad_sequences(token.texts_to_sequences(x), maxlen=70)\n",
        "\n",
        "x_train_seq, x_test_seq, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# y_train = to_categorical(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLrjOn-NuWk-"
      },
      "source": [
        "*Training, Predicting Test data and Calculating Accuracy*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbeu5Sdjfrai"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "def NN_model_training(model, x_train, y_train, x_test, y_test):\n",
        "\n",
        "  model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.2 )\n",
        "\n",
        "  y_pred = model.predict_classes(x_test)\n",
        "\n",
        "  return accuracy_score(y_pred, y_test)\n",
        "\n",
        "accuracyAnalysis = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDwWug9vuvXN"
      },
      "source": [
        "*LSTM Model Analysis*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcf0ehWQJflu",
        "outputId": "fb711bd8-eb8d-4d9a-b669-3ca1bf4012c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "def LSTM_classification(x_train_seq):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))\n",
        "  model.add(layers.LSTM(100))\n",
        "  model.add(layers.Dense(50, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = LSTM_classification(x_train_seq)\n",
        "\n",
        "accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)\n",
        "\n",
        "print(\"LSTM accuracy score: \", accuracy)\n",
        "accuracyAnalysis[\"LSTM accuracy score\"] = accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 70, 300)           54712200  \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 54,877,701\n",
            "Trainable params: 54,877,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/10\n",
            "32000/32000 [==============================] - 185s 6ms/step - loss: 0.4183 - accuracy: 0.8048 - val_loss: 0.3705 - val_accuracy: 0.8336\n",
            "Epoch 2/10\n",
            "32000/32000 [==============================] - 184s 6ms/step - loss: 0.1927 - accuracy: 0.9258 - val_loss: 0.4473 - val_accuracy: 0.8324\n",
            "Epoch 3/10\n",
            "32000/32000 [==============================] - 184s 6ms/step - loss: 0.0840 - accuracy: 0.9698 - val_loss: 0.5676 - val_accuracy: 0.8290\n",
            "Epoch 4/10\n",
            "32000/32000 [==============================] - 181s 6ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 0.6948 - val_accuracy: 0.8166\n",
            "Epoch 5/10\n",
            "32000/32000 [==============================] - 183s 6ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.8057 - val_accuracy: 0.8209\n",
            "Epoch 6/10\n",
            "32000/32000 [==============================] - 182s 6ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.9516 - val_accuracy: 0.8224\n",
            "Epoch 7/10\n",
            "32000/32000 [==============================] - 179s 6ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.9263 - val_accuracy: 0.8110\n",
            "Epoch 8/10\n",
            "32000/32000 [==============================] - 178s 6ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.0607 - val_accuracy: 0.8150\n",
            "Epoch 9/10\n",
            "32000/32000 [==============================] - 178s 6ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 1.1512 - val_accuracy: 0.8205\n",
            "Epoch 10/10\n",
            "32000/32000 [==============================] - 183s 6ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 1.2706 - val_accuracy: 0.8200\n",
            "LSTM accuracy score:  0.8191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u29EUTEZD9UD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUvC-niUu2Ul"
      },
      "source": [
        "*CNN Model Analysis*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUQrHb-9zvlW",
        "outputId": "12a8efd5-e59b-4221-b380-a3856c1583d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "def CNN_classification(x_train_seq):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))\n",
        "  model.add(layers.SpatialDropout1D(0.3))\n",
        "  model.add(layers.Convolution1D(100, 3, activation='relu'))\n",
        "  model.add(layers.GlobalMaxPool1D())\n",
        "  model.add(layers.Dense(100, activation='relu'))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "model = CNN_classification(x_train_seq)\n",
        "\n",
        "accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)\n",
        "\n",
        "print(\"CNN accuracy score: \", accuracy)\n",
        "accuracyAnalysis[\"CNN accuracy score\"] = accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 70, 300)           54712200  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 70, 300)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 68, 100)           90100     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 54,812,501\n",
            "Trainable params: 54,812,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/10\n",
            "32000/32000 [==============================] - 67s 2ms/step - loss: 0.4494 - accuracy: 0.7777 - val_loss: 0.3502 - val_accuracy: 0.8460\n",
            "Epoch 2/10\n",
            "32000/32000 [==============================] - 63s 2ms/step - loss: 0.2249 - accuracy: 0.9118 - val_loss: 0.3586 - val_accuracy: 0.8493\n",
            "Epoch 3/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 0.4767 - val_accuracy: 0.8338\n",
            "Epoch 4/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.6315 - val_accuracy: 0.8374\n",
            "Epoch 5/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.7022 - val_accuracy: 0.8345\n",
            "Epoch 6/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.8325 - val_accuracy: 0.8322\n",
            "Epoch 7/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.8847 - val_accuracy: 0.8324\n",
            "Epoch 8/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.8901 - val_accuracy: 0.8305\n",
            "Epoch 9/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.9621 - val_accuracy: 0.8149\n",
            "Epoch 10/10\n",
            "32000/32000 [==============================] - 62s 2ms/step - loss: 0.0092 - accuracy: 0.9962 - val_loss: 0.9660 - val_accuracy: 0.8261\n",
            "CNN accuracy score:  0.8307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv5gKnp9u6BN"
      },
      "source": [
        "*GRU Model Analysis*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjb6wwBq22bY",
        "outputId": "8d4ecf5a-5416-4258-b58f-2265fe36883b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "def GRU_classification(x_train_seq):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))\n",
        "  model.add(layers.SpatialDropout1D(0.3))\n",
        "  model.add(layers.GRU(100))\n",
        "  model.add(layers.Dense(50, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = GRU_classification(x_train_seq)\n",
        "\n",
        "accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)\n",
        "\n",
        "print(\"GRU accuracy score: \", accuracy)\n",
        "accuracyAnalysis[\"GRU accuracy score\"] = accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 70, 300)           54712200  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 70, 300)           0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100)               120300    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 54,837,601\n",
            "Trainable params: 54,837,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/10\n",
            "32000/32000 [==============================] - 210s 7ms/step - loss: 0.4295 - accuracy: 0.7974 - val_loss: 0.3586 - val_accuracy: 0.8421\n",
            "Epoch 2/10\n",
            "32000/32000 [==============================] - 208s 7ms/step - loss: 0.2079 - accuracy: 0.9191 - val_loss: 0.4036 - val_accuracy: 0.8301\n",
            "Epoch 3/10\n",
            "32000/32000 [==============================] - 209s 7ms/step - loss: 0.0868 - accuracy: 0.9698 - val_loss: 0.4874 - val_accuracy: 0.8288\n",
            "Epoch 4/10\n",
            "32000/32000 [==============================] - 210s 7ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.6437 - val_accuracy: 0.8278\n",
            "Epoch 5/10\n",
            "32000/32000 [==============================] - 209s 7ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.8484 - val_accuracy: 0.8192\n",
            "Epoch 6/10\n",
            "32000/32000 [==============================] - 210s 7ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.9196 - val_accuracy: 0.8230\n",
            "Epoch 7/10\n",
            "32000/32000 [==============================] - 211s 7ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.0610 - val_accuracy: 0.8179\n",
            "Epoch 8/10\n",
            "32000/32000 [==============================] - 209s 7ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.2307 - val_accuracy: 0.8210\n",
            "Epoch 9/10\n",
            "32000/32000 [==============================] - 209s 7ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.3058 - val_accuracy: 0.8138\n",
            "Epoch 10/10\n",
            "32000/32000 [==============================] - 208s 7ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.2112 - val_accuracy: 0.8190\n",
            "GRU accuracy score:  0.8229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUNJqdr_u_oJ"
      },
      "source": [
        "*BiDirectional GRU Model Analysis*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeSP73G74H6d",
        "outputId": "9db47578-71fd-429a-f129-ee7f0259cf61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "def BiDirectional_GRU_classification(x_train_seq):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))\n",
        "  model.add(layers.SpatialDropout1D(0.3))\n",
        "  model.add(layers.Bidirectional(layers.GRU(100)))\n",
        "  model.add(layers.Dense(50, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "model = BiDirectional_GRU_classification(x_train_seq)\n",
        "\n",
        "accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)\n",
        "\n",
        "print(\"BiDirectional GRU accuracy score: \", accuracy)\n",
        "accuracyAnalysis[\"BiDirectional GRU accuracy score\"] = accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 70, 300)           54712200  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_3 (Spatial (None, 70, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               240600    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 50)                10050     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 54,962,901\n",
            "Trainable params: 54,962,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/10\n",
            "32000/32000 [==============================] - 349s 11ms/step - loss: 0.4267 - accuracy: 0.7990 - val_loss: 0.3418 - val_accuracy: 0.8491\n",
            "Epoch 2/10\n",
            "32000/32000 [==============================] - 348s 11ms/step - loss: 0.1966 - accuracy: 0.9236 - val_loss: 0.3726 - val_accuracy: 0.8372\n",
            "Epoch 3/10\n",
            "32000/32000 [==============================] - 345s 11ms/step - loss: 0.0647 - accuracy: 0.9771 - val_loss: 0.6093 - val_accuracy: 0.8303\n",
            "Epoch 4/10\n",
            "32000/32000 [==============================] - 346s 11ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.7835 - val_accuracy: 0.8230\n",
            "Epoch 5/10\n",
            "32000/32000 [==============================] - 342s 11ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.9875 - val_accuracy: 0.8217\n",
            "Epoch 6/10\n",
            "32000/32000 [==============================] - 343s 11ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.0585 - val_accuracy: 0.8201\n",
            "Epoch 7/10\n",
            "32000/32000 [==============================] - 345s 11ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 1.1439 - val_accuracy: 0.8188\n",
            "Epoch 8/10\n",
            "32000/32000 [==============================] - 350s 11ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 1.0433 - val_accuracy: 0.8170\n",
            "Epoch 9/10\n",
            "32000/32000 [==============================] - 347s 11ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.1734 - val_accuracy: 0.8161\n",
            "Epoch 10/10\n",
            "32000/32000 [==============================] - 345s 11ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.3238 - val_accuracy: 0.8166\n",
            "BiDirectional GRU accuracy score:  0.8211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVf_ETP1vDt_"
      },
      "source": [
        "*BiDirectional CNN Analysis*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xMurkzd4i9B",
        "outputId": "2792786a-ff86-4760-cabf-9dce8fd3ed79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "def BiDirectional_CNN_classification(x_train_seq):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(input_dim=len(word_index)+1, output_dim=300, input_length=x_train_seq.shape[1]))\n",
        "  model.add(layers.SpatialDropout1D(0.3))\n",
        "  model.add(layers.Bidirectional(layers.GRU(50, return_sequences=True)))\n",
        "  model.add(layers.Convolution1D(100, 3, activation='relu'))\n",
        "  model.add(layers.GlobalMaxPool1D())\n",
        "  model.add(layers.Dense(100, activation='relu'))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "model = BiDirectional_CNN_classification(x_train_seq)\n",
        "\n",
        "accuracy = NN_model_training(model, x_train_seq, y_train, x_test_seq, y_test)\n",
        "\n",
        "print(\"BiDirectional CNN accuracy score: \", accuracy)\n",
        "accuracyAnalysis[\"BiDirectional CNN accuracy score\"] = accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 70, 300)           54712200  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_4 (Spatial (None, 70, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 70, 100)           105300    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 68, 100)           30100     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 54,857,801\n",
            "Trainable params: 54,857,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/10\n",
            "32000/32000 [==============================] - 349s 11ms/step - loss: 0.4220 - accuracy: 0.7970 - val_loss: 0.3311 - val_accuracy: 0.8537\n",
            "Epoch 2/10\n",
            "32000/32000 [==============================] - 348s 11ms/step - loss: 0.2030 - accuracy: 0.9206 - val_loss: 0.3829 - val_accuracy: 0.8530\n",
            "Epoch 3/10\n",
            "32000/32000 [==============================] - 346s 11ms/step - loss: 0.0788 - accuracy: 0.9718 - val_loss: 0.5186 - val_accuracy: 0.8403\n",
            "Epoch 4/10\n",
            "32000/32000 [==============================] - 346s 11ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.6056 - val_accuracy: 0.8365\n",
            "Epoch 5/10\n",
            "32000/32000 [==============================] - 344s 11ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.8807 - val_accuracy: 0.8365\n",
            "Epoch 6/10\n",
            "32000/32000 [==============================] - 348s 11ms/step - loss: 0.0130 - accuracy: 0.9952 - val_loss: 1.0877 - val_accuracy: 0.8276\n",
            "Epoch 7/10\n",
            "32000/32000 [==============================] - 346s 11ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 1.0861 - val_accuracy: 0.8284\n",
            "Epoch 8/10\n",
            "32000/32000 [==============================] - 346s 11ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 1.2666 - val_accuracy: 0.8292\n",
            "Epoch 9/10\n",
            "32000/32000 [==============================] - 345s 11ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.1423 - val_accuracy: 0.8223\n",
            "Epoch 10/10\n",
            "32000/32000 [==============================] - 345s 11ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 1.2789 - val_accuracy: 0.8241\n",
            "BiDirectional CNN accuracy score:  0.8291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK6QWVAL2SFb",
        "outputId": "6584a203-7825-44b6-9870-43248720ef5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "accuracyAnalysis\n",
        "metrics = sorted(accuracyAnalysis.items(), key=(lambda x: x[1]), reverse=True)\n",
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('CNN accuracy score', 0.8307),\n",
              " ('BiDirectional CNN accuracy score', 0.8291),\n",
              " ('GRU accuracy score', 0.8229),\n",
              " ('BiDirectional GRU accuracy score', 0.8211),\n",
              " ('LSTM accuracy score', 0.8191)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-c8Aemu5VdL",
        "outputId": "fe3511b5-e9f9-418b-dd1f-e5672c05717a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "!matplotlib inline\n",
        "\n",
        "x_metrics = []\n",
        "y_metrics = []\n",
        "\n",
        "for i in metrics:\n",
        "  x_metrics.append(i[0])\n",
        "  y_metrics.append(i[1])\n",
        "\n",
        "\n",
        "plt.xlabel(\"Classification Models for text Data Using DL Techniques\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "# plt.plot(x_metrics_lemmet, y_metrics_lemmet)\n",
        "plt.bar(x_metrics, y_metrics)\n",
        "plt.xticks(x_metrics, rotation='vertical')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: matplotlib: command not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5eWmOnSZM9U"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}